✅ Overview of the Architecture
css
Copy
Edit
[Client (Browser/App)]
    ↳ Requests an upload URL from your backend

[Your Backend (Node.js)]
    ↳ Generates a signed URL from S3
    ↳ Sends it back to the client

[Client (again)]
    ↳ Uploads the file directly to S3 using that signed URL

[S3]
    ↳ Stores the file
🔧 1. Set Up Your S3 Bucket
Go to S3 Console and:

Create a bucket (e.g., my-app-uploads)

Disable "Block all public access" unless you plan to restrict access via signed URLs

Enable CORS for browser-based uploads:

Example CORS Configuration for S3 bucket:
xml
Copy
Edit
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["PUT", "POST", "GET"],
    "AllowedOrigins": ["*"], // Or restrict to your frontend domain
    "ExposeHeaders": []
  }
]
🛠️ 2. Backend Setup (Node.js + Express)
Install dependencies:
bash
Copy
Edit
npm install express aws-sdk dotenv
Folder Structure:
bash
Copy
Edit
project/
├── index.js
├── .env
.env (Add your AWS credentials securely)
ini
Copy
Edit
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=my-app-uploads
index.js
js
Copy
Edit
const express = require('express');
const AWS = require('aws-sdk');
require('dotenv').config();
const cors = require('cors');

const app = express();
app.use(cors());
const port = 3000;

// Configure AWS SDK
const s3 = new AWS.S3({
  region: process.env.AWS_REGION,
  accessKeyId: process.env.AWS_ACCESS_KEY_ID,
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
});

// API endpoint to get a signed URL
app.get('/get-upload-url', async (req, res) => {
  const { fileName, fileType } = req.query;

  if (!fileName || !fileType) {
    return res.status(400).json({ error: 'Missing fileName or fileType' });
  }

  const s3Params = {
    Bucket: process.env.S3_BUCKET_NAME,
    Key: `uploads/${Date.now()}_${fileName}`,
    Expires: 60, // URL expires in 60 seconds
    ContentType: fileType,
    ACL: 'public-read',
  };

  try {
    const uploadURL = await s3.getSignedUrlPromise('putObject', s3Params);
    res.json({ uploadURL });
  } catch (err) {
    console.error('Error generating signed URL:', err);
    res.status(500).json({ error: 'Could not generate signed URL' });
  }
});

app.listen(port, () => {
  console.log(`Server running on http://localhost:${port}`);
});
💻 3. Frontend Example (HTML + JS)
Upload a file using the signed URL:
html
Copy
Edit
<input type="file" id="fileInput" />
<script>
  const input = document.getElementById('fileInput');

  input.addEventListener('change', async () => {
    const file = input.files[0];
    if (!file) return;

    // Get signed URL
    const res = await fetch(`http://localhost:3000/get-upload-url?fileName=${file.name}&fileType=${file.type}`);
    const data = await res.json();

    // Upload the file to S3
    const upload = await fetch(data.uploadURL, {
      method: 'PUT',
      headers: {
        'Content-Type': file.type
      },
      body: file
    });

    if (upload.ok) {
      alert('Upload successful!');
    } else {
      alert('Upload failed.');
    }
  });
</script>
🧼 Best Practices (Once It’s Working)
✅ Save the uploaded file’s URL or S3 key to your database.

✅ Use more secure CORS (AllowedOrigins) for production.

✅ Optionally use UUIDs instead of timestamps for filenames.

✅ Use a .env file or a secret manager to manage credentials.

✅ Enable logging and alerts in S3 for file access and errors.

Want to Add:
✅ Multi-file upload?

✅ Restrict file types or size?

✅ Thumbnail/image processing with Lambda?

Let me know what extras you want, and I’ll help you build them in.